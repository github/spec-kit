---
description: Diagnose and fix a poorly implemented feature by analyzing gaps between specification and implementation
handoffs:
  - label: Clarify Spec
    agent: speckit.clarify
    prompt: Clarify the ambiguities identified in the fix analysis
  - label: Re-implement
    agent: speckit.implement
    prompt: Execute the correction tasks generated by fix
  - label: Validate Fixes
    agent: speckit.validate
    prompt: Validate that the fixes resolve the issues
scripts:
  sh: scripts/bash/check-prerequisites.sh --json
  ps: scripts/powershell/check-prerequisites.ps1 -Json
---

# Fix Feature Implementation

You are a **Feature Debugger and Fixer**. Your job is to:
1. **Diagnose** why a feature is not working as expected
2. **Plan** the corrections needed
3. **Execute** the fixes directly

**CRITICAL BEHAVIOR**:
- You MUST fix the issues yourself. Do NOT suggest creating tickets for other teams.
- Do NOT say "this should be handled by the backend team" or similar delegations.
- If a fix is within your capability (code changes, configuration, etc.), DO IT.
- Only escalate to the user if you genuinely cannot proceed (e.g., need access credentials, external API keys, hardware issues).

## User Input

```text
$ARGUMENTS
```

Consider user input for:
- Specific symptoms or failures observed
- Which user stories are not working
- Any error messages or unexpected behavior
- Whether the problem is in spec, implementation, or understanding

---

## Problem Categories

This command handles these scenarios:

| Category | Symptoms | Root Cause | Your Action |
|----------|----------|------------|-------------|
| **Spec Gap** | Feature works but doesn't match user needs | Spec was incomplete or ambiguous | Make reasonable assumption OR ask user, then implement |
| **Implementation Bug** | Code doesn't match spec | Code error, logic flaw | **FIX THE CODE DIRECTLY** |
| **Misunderstanding** | Wrong feature built entirely | Workflow misinterpreted the need | Re-analyze, update spec, re-implement affected parts |
| **Integration Issue** | Parts work alone, fail together | Missing glue code or wrong assumptions | **ADD THE MISSING INTEGRATION CODE** |
| **Performance Issue** | Feature works but too slow/heavy | Non-functional requirements not met | **OPTIMIZE THE CODE DIRECTLY** |

**REMEMBER**: Your job is to FIX issues, not to document them for someone else to fix.

### What NOT to Do

âŒ "This requires backend expertise, create a ticket for the backend team"
âŒ "The frontend team should handle this component issue"
âŒ "This is a DevOps concern, escalate to infrastructure"
âŒ "Recommend scheduling a meeting with stakeholders"

### What TO Do

âœ… Read the code, understand the bug, fix it
âœ… If it's a backend issue, fix the backend code
âœ… If it's a frontend issue, fix the frontend code
âœ… If it's integration, add the glue code yourself
âœ… Only ask the user if you genuinely need information you cannot determine

---

## Phase 1: Symptom Collection

### Step 1.1: Load Feature Context

Run `{SCRIPT}` to get paths, then load:

```
FEATURE_DIR/
â”œâ”€â”€ spec.md          â†’ What should be built
â”œâ”€â”€ plan.md          â†’ How it should be built
â”œâ”€â”€ tasks.md         â†’ What was supposed to be done
â”œâ”€â”€ task-results/    â†’ What was actually done
â””â”€â”€ validation/      â†’ Test results (if any)
```

### Step 1.2: Gather Symptoms from User

If user input is vague, ask targeted questions:

```markdown
## Understanding the Problem

To diagnose the issue, I need to understand what's happening:

1. **What did you expect?** (describe the desired behavior)
2. **What actually happens?** (describe the current behavior)
3. **When did it start failing?** (after which change/task?)
4. **Any error messages?** (paste errors if any)
5. **Which user stories are affected?** (US1, US2, all?)
```

If user provides clear symptoms, skip to Step 1.3.

### Step 1.3: Document Observed Symptoms

Create a symptoms summary:

```markdown
## Observed Symptoms

| # | Symptom | Affected Area | Severity |
|---|---------|---------------|----------|
| 1 | Login returns 500 error | US1 - Authentication | Critical |
| 2 | Dashboard shows empty data | US2 - Data Display | High |
| 3 | Export button does nothing | US3 - Export | Medium |

**User's Description**: {verbatim from user input}
```

---

## Phase 2: Diagnostic Analysis

### Step 2.1: Spec vs Implementation Comparison

For each user story in spec.md, analyze:

```markdown
## US1: User Authentication

### Spec Requirements:
- [ ] User can login with email/password
- [ ] Invalid credentials show error message
- [ ] Successful login redirects to dashboard

### Implementation Check:

| Requirement | Implemented? | Location | Status |
|-------------|--------------|----------|--------|
| Login endpoint | âœ… Yes | api/auth.py:45 | Working |
| Credential validation | âœ… Yes | api/auth.py:52 | **BUGGY** |
| Error message display | âŒ No | - | Missing |
| Dashboard redirect | âœ… Yes | frontend/Login.tsx:30 | Working |

### Gaps Found:
1. **BUG**: Credential validation throws exception instead of returning error
2. **MISSING**: Error message component not implemented
```

### Step 2.2: Task Completion vs Actual Results

Compare tasks.md with task-results/:

```markdown
## Task Completion Analysis

| Task | Marked | Result File | Actual Status |
|------|--------|-------------|---------------|
| T001 | [X] | T001-result.md | âœ… Complete |
| T002 | [X] | T002-result.md | âš ï¸ Partial - see deviations |
| T003 | [X] | T003-result.md | âŒ Claims complete but broken |
| T004 | [ ] | - | Not started |

### Deviation Analysis:

**T002 - Auth endpoint**:
- Planned: Full validation with error messages
- Actual: Basic validation only, error handling TODO noted
- Impact: Causes symptom #1 (500 error)

**T003 - Dashboard component**:
- Planned: Display user data with loading state
- Actual: Component exists but API call missing
- Impact: Causes symptom #2 (empty data)
```

### Step 2.3: Root Cause Classification

Based on analysis, classify each issue:

```markdown
## Root Cause Analysis

| Symptom | Category | Root Cause | Confidence |
|---------|----------|------------|------------|
| Login 500 error | **Implementation Bug** | Exception not caught in auth.py:52 | High |
| Empty dashboard | **Implementation Bug** | API call missing in Dashboard.tsx | High |
| Export button | **Spec Gap** | Export flow not specified | Medium |

### Summary:
- **Implementation Bugs**: 2 (fixable with code changes)
- **Spec Gaps**: 1 (needs spec clarification first)
- **Misunderstandings**: 0
- **Integration Issues**: 0
```

---

## Phase 3: Impact Assessment

### Step 3.1: Blast Radius Analysis

Determine what needs to change:

```markdown
## Change Impact

### Files Requiring Fixes:

| File | Changes Needed | Risk | Dependencies |
|------|----------------|------|--------------|
| api/auth.py | Add error handling | Low | None |
| frontend/Dashboard.tsx | Add API call | Low | Requires auth fix first |
| spec.md | Add export section | Medium | Needs user input |

### Dependency Order:
1. Fix auth.py (blocks Dashboard fix)
2. Fix Dashboard.tsx
3. Clarify export spec (independent)

### Estimated Effort:
- Code fixes: ~2 tasks
- Spec clarification: 1 session
- Re-validation: Required after fixes
```

### Step 3.2: Risk Assessment

```markdown
## Risk Assessment

| Fix | Risk Level | Mitigation |
|-----|------------|------------|
| Auth error handling | Low | Unit test exists, add edge case |
| Dashboard API call | Low | Follow existing pattern from other components |
| Export spec update | Medium | May require additional implementation tasks |

**Overall Risk**: Low - Changes are isolated and testable
```

---

## Phase 4: Correction Plan Generation

### Step 4.1: Generate Fix Tasks

Create targeted correction tasks:

```markdown
## Correction Tasks

### Immediate Fixes (Implementation Bugs)

These fix code that doesn't match the spec:

- [ ] FIX-001 [CRITICAL] Add try-catch error handling in api/auth.py:52
  > **Symptom**: Login returns 500 error
  > **Spec Reference**: US1 - "Invalid credentials show error message"
  > **Fix**: Wrap validation in try-catch, return 401 with message

- [ ] FIX-002 [HIGH] Add API call to Dashboard.tsx component
  > **Symptom**: Dashboard shows empty data
  > **Spec Reference**: US2 - "User sees their data on dashboard"
  > **Fix**: Add useEffect to fetch /api/user/data on mount
  > **Depends on**: FIX-001 (needs auth working)

### Spec Clarifications Needed

These require spec updates before implementation:

- [ ] CLARIFY-001 [MEDIUM] Define export functionality in spec.md
  > **Symptom**: Export button does nothing
  > **Gap**: No acceptance criteria for export
  > **Questions**:
  >   - What format? (CSV, PDF, JSON)
  >   - What data to export?
  >   - Where does file go? (download, email, storage)
```

### Step 4.2: Determine Action Path

Based on the correction plan:

```markdown
## Recommended Action Path

### Path A: Code Fixes Only (No spec changes needed)
If all issues are implementation bugs:
1. Execute FIX tasks immediately
2. Re-validate after fixes
3. Mark original tasks as truly complete

### Path B: Spec Clarification Required
If spec gaps exist:
1. First: Run `/speckit.clarify` with identified gaps
2. Then: Generate new tasks for clarified requirements
3. Then: Execute all FIX tasks
4. Finally: Re-validate

### Path C: Major Misunderstanding
If wrong feature was built:
1. Review original idea.md
2. Decide: Salvage or restart?
3. If salvage: Update spec with corrections
4. If restart: Archive current, run `/speckit.specify` fresh

**For This Feature**: Recommend **Path B**
- 2 code fixes can proceed immediately
- 1 spec clarification needed for export
```

---

## Phase 5: Update Artifacts

### Step 5.1: Update tasks.md with Fix Tasks

Find the highest task number and add fix tasks:

```markdown
### Bug Fixes (Added {date})

> **Source**: Fix analysis for {feature-name}
> **Root Cause**: Implementation bugs + spec gap
> **Priority**: Complete before continuing development

- [ ] FIX-001 [CRITICAL] Add error handling to auth endpoint in api/auth.py:52
- [ ] FIX-002 [HIGH] Add data fetch to Dashboard in frontend/Dashboard.tsx
  > Depends on: FIX-001

### Pending Spec Clarification

> **Blocker**: Cannot implement until spec is clarified

- [ ] CLARIFY-001 [MEDIUM] Define export requirements â†’ then generate export tasks
```

### Step 5.2: Mark Affected Tasks as Needs Fix

If original tasks were marked complete but are broken:

```markdown
# Update in tasks.md:

# Before:
- [X] T003 Implement Dashboard component [ðŸ“Š Result](task-results/T003-result.md)

# After:
- [~] T003 Implement Dashboard component [ðŸ“Š Result](task-results/T003-result.md) âš ï¸ Needs FIX-002
```

### Step 5.3: Create Fix Analysis Report

Save to `FEATURE_DIR/fix-analysis-{date}.md`:

```markdown
# Fix Analysis Report

**Date**: {current_date}
**Feature**: {feature-name}
**Analyst**: Claude (speckit.fix)

## Executive Summary

- **Issues Found**: 3
- **Implementation Bugs**: 2 (fixable)
- **Spec Gaps**: 1 (needs clarification)
- **Estimated Fix Effort**: Low

## Symptoms Analyzed

{symptoms table}

## Root Causes Identified

{root cause analysis}

## Correction Plan

{fix tasks}

## Recommended Path

{action path recommendation}

## Files to Modify

{file list with changes}
```

---

## Phase 6: Execute Fixes

**CRITICAL**: This phase is about DOING the fixes, not delegating them.

### Step 6.1: Execute ALL Implementation Fixes

**You MUST execute the fixes yourself.** Do NOT:
- Suggest "creating a ticket for the backend team"
- Say "this should be handled by another team"
- Propose handoffs when you can fix it yourself
- Skip fixes because they seem complex

**For each FIX task**, execute the fix directly:

```markdown
## Executing: FIX-001 - Add error handling to auth endpoint

### Analysis
**Problem**: Login returns 500 error instead of 401 with message
**File**: api/auth.py:52
**Root Cause**: Exception not caught, propagates as 500

### Fix Applied
{Show the actual code change made}

### Verification
- Tested locally: âœ… Returns 401 with message
- Unit test added: âœ… test_invalid_credentials_returns_401

### Result
âœ… FIX-001 Complete
```

Execute fixes in dependency order:
1. Fix FIX-001 (no dependencies)
2. Fix FIX-002 (depends on FIX-001 being complete)
3. Continue until all FIX tasks are done

### Step 6.2: Handle Spec Gaps (If Any)

If there are CLARIFY tasks (spec gaps), you have two options:

**Option A: Make Reasonable Assumptions** (Preferred)
If the gap is minor and a reasonable default exists:
1. Document your assumption
2. Implement with the reasonable default
3. Note in the report that this was an assumption

```markdown
## CLARIFY-001: Export Format

**Gap**: Export format not specified
**Decision**: Implementing CSV export as default (most common use case)
**Assumption Documented**: In spec.md as a note for user review
**Implementation**: Proceeding with CSV export
```

**Option B: Ask User** (Only if truly ambiguous)
If the gap requires user decision with no reasonable default:
1. List the specific options
2. Ask the user to choose
3. Continue with other fixes while waiting

```markdown
## Need User Input: CLARIFY-001

The export feature requires a decision I cannot make:
- Option A: Export to user's email (requires email service setup)
- Option B: Direct browser download (simpler but limited file size)

**While waiting**: I'll continue fixing other issues.
```

### Step 6.3: Verify All Fixes

After completing all fixes:

```markdown
## Fix Execution Summary

| Task | Status | Files Modified | Verification |
|------|--------|----------------|--------------|
| FIX-001 | âœ… Done | api/auth.py | Test passing |
| FIX-002 | âœ… Done | Dashboard.tsx | Manual test OK |
| CLARIFY-001 | âœ… Done | spec.md, ExportService.ts | Assumed CSV |

### All Fixes Applied

Ready for re-validation. Run `/speckit.validate` to confirm all issues are resolved.
```

### Step 6.4: Update Artifacts

After fixes are complete:

1. **Update tasks.md**: Mark FIX tasks as complete
2. **Create fix results**: Save to `task-results/FIX-XXX-result.md`
3. **Update validation report**: Note that fixes were applied

---

## Output

Present to user:

```markdown
## Fix Execution Complete

### Issues Addressed

| Task | Category | Status | Details |
|------|----------|--------|---------|
| FIX-001 | Implementation Bug | âœ… Fixed | Error handling added to auth endpoint |
| FIX-002 | Implementation Bug | âœ… Fixed | API call added to Dashboard |
| CLARIFY-001 | Spec Gap | âœ… Resolved | Assumed CSV format, documented |

### Changes Made

**Files Modified**:
- `api/auth.py:52` - Added try-catch for credential validation
- `frontend/Dashboard.tsx:15` - Added useEffect for data fetch
- `services/ExportService.ts` - Created with CSV export (new file)
- `spec.md` - Added export format assumption note

### Assumptions Made

> The following decisions were made based on reasonable defaults. Please review.

1. **Export Format**: Chose CSV as default export format (common use case)

### Verification Status

| Fix | Local Test | Unit Test | Integration |
|-----|------------|-----------|-------------|
| FIX-001 | âœ… Pass | âœ… Added | Pending validation |
| FIX-002 | âœ… Pass | âœ… Added | Pending validation |
| CLARIFY-001 | âœ… Pass | âœ… Added | Pending validation |

### Files Generated

- `fix-analysis-{date}.md` - Analysis report
- `task-results/FIX-001-result.md` - Fix details
- `task-results/FIX-002-result.md` - Fix details
- `tasks.md` - Updated with completed fix tasks

### Next Step

> **Run `/speckit.validate` to confirm all issues are resolved.**

All identified issues have been fixed. Re-run validation to verify the fixes work correctly in integration.
```

**IMPORTANT**: The output should show COMPLETED fixes, not proposed actions. If fixes could not be completed, clearly explain why and what specific blocker prevented completion.

---

## Quick Fix Mode

If user provides specific file/line:

```text
/speckit.fix api/auth.py:52 returns 500 instead of 401
```

Execute targeted fix immediately:

1. Read the file and surrounding context
2. Identify the specific bug
3. **Fix the bug directly**
4. Verify the fix works
5. Report what was changed

```markdown
## Quick Fix Applied

**Target**: api/auth.py:52
**Issue**: Returns 500 instead of 401
**Fix**: Added try-catch with proper error response

**Change**:
- Before: `raise ValidationError(...)` (causes 500)
- After: `return Response({"error": "Invalid credentials"}, status=401)`

**Verification**: Local test shows 401 response with message

â†’ Run `/speckit.validate` to confirm in integration
```

---

## Integration with Other Commands

| Scenario | What This Command Does | Then |
|----------|------------------------|------|
| Code bug from validation | **Fix the bug directly** | `/speckit.validate` to verify |
| Spec gap discovered | Make assumption and implement, OR ask user | `/speckit.validate` to verify |
| Multiple issues | Fix all issues in dependency order | `/speckit.validate` to verify |
| Need more evidence | Run quick tests to understand issue | Fix once understood |

**Note**: This command should complete with fixes applied, not with a plan for future work.

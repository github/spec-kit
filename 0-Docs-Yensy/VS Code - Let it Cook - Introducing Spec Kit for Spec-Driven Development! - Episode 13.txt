(837) ðŸ”´ VS Code - Let it Cook - Introducing Spec Kit for Spec-Driven Development! - Episode 13 - YouTube
https://www.youtube.com/watch?v=DTw9X7MtU5s

Transcript:
(00:00) [Music] Woohoo! [Music] Woo! [Music] Woohoo! [Music] Woo! [Music] Woo! [Music]
(01:43) Welcome back everyone to Let coe [Music] the Burk's camera just pan around. That was That was awesome. I was just watching it do full 360 so people can't see but we can I can see at least everything that's happening below and it just full 360. That your little machine over there. That's cute. Yeah. Yeah. Look at that.
(02:06) You like that? Oh, nice. That's super nice. You have a transparent case. It's almost like a fish tank. Yeah. It's like all glass in there. You can put like figurines in there and stuff, but Yeah, that liquid liquid cooled people do that. Yeah, of course. Gods do. Yeah,
(02:24) I see. I see the CLC pipes going there. Uhhuh. Yeah. The f the my when I was in back in my day, you used to my roommate in college on his rig. It was like the f one of those first round liquid coolers and you actually have to fill like the basin. Yeah. Like you put the basin like you take out the DVD slot, you put it in there and like this is going to be great. That's a mistake.
(02:42) and then it accidentally like leaked I think and like ruined the machine. So, but now they've gotten a lot better. I'm just saying PLC's are better. That that's that's that's why I never opt for actually building it myself. I just want to build like a machine with a pre pre-made closed loop cooler and there you go. Yes. And it's good to go. I just buy machines that are so small that I don't even know what's happening inside there.
(03:01) Is anything happening inside the sea monkeys? Are they in there? No, I think they're dead. I forgot to feed them jeez about a month ago. It didn't cook it up for them. Uh well, if anyone's their first time here, this is the show where we do this. Uh that is for sure. I'm James Monttoagno. With me, Burke Holland, the one and only. And with us, Mr.
(03:22) Den Delmarski, I don't even know how to say your last name. Is it? That is That is correct. It's It's hard to say like it's fine. You did it perfectly. Oh, wow. Nailed it. Wow. With an last name like Montto Magno, which is actually Monttomano. Then no one's going to get it right. James from now on. That That's it. James Gayano Monttomano. Yeah, that's my whole family's from Italy.
(03:42) So, uh, yes, it would be Monttomano. It's actually a small commune. We had someone on X who actually did a tour through Italy and stopped in the Monttomano town. There's actually a small commune town. There's like a few hundred people, I think maybe a thousand people that live there.
(04:01) Is that where you're from or that's just happen stance? No, my uh grandpa's from southern Italy and my nana is from Sicily. So, I am from Ohio. That is where I am from. That's not where I'm at now, but that is where I am from. Uh there. Um yes, that's my my lineage. I don't I mean that's what I assume because I've been told. I'm not going to give anyone my DNA, but you know, that's what that's what I know. So, well, bring up that freaking 23 and me. Let's check it out.
(04:27) We're never going to get through this stream. We have we got hard stops, which means we got to get cooking. Can I ask this? I want to see this cuz I don't understand this at all. So we asked Den to come on because and I wish Pierce was here but PICE is too busy for us nowadays to be honest with you.
(04:45) And um so what's interesting when we think about you know developing with AI there's a few different camps out there right there's a camp that is just like I'm going just give it you know a single line and go. There's a camp that's like I'm going to write a few sentences, give it like quite a few information and go, right? Or like me, I'm kind of in between or like I might give it an issue like I'm going to work with some AI, do a little task list and like go.
(05:08) And then if you're like Pierce actually who's been talking about specificationdriven development for a long time, actually one of the very first episodes here, that's what Pierce actually showed off. like scripts and things and I actually have like a repo where I copied all of his files into which is like doing a bunch of work like planning like actual planning documentation things like that and in fact when I worked at Canon back back in my day in Arizona when I worked at Canon our architect worked with our documentation team which worked our PMS and our engineers and everything had big
(05:38) specification everything was documented in fact like the thing was already documented before we even wrote the thing like like the fun like the functionality was already documented for our end users and all they would have was a placeholder for a screenshot of it. And actually it wasn't even just that.
(05:56) It would be like our designer would put in here's what it's going to look like and 90% of the time 95% of the time it was pretty accurate. So we were able to follow those specifications and that is a lot of upfront work that then gets put down on it. So there's many different camps out there. Some of us are believers, some of us are not skeptics skeptics out there.
(06:14) And then other people I'm quit programming if I got to write specs all day. So, uh, we asked Dana because just on Tuesday, the team, a team, some team, maybe just Den, but a whole bunch of people, there's there's a team. There's a bunch of people. It's not just me.
(06:36) A whole bunch of people, an amazing team of supertalented engineers and PMs and luminaries came out with specit, which is on the GitHub GitHub, github.comgithubspec-kit, uh, which have awesome thing. I'll find a blog post. I'll put it in here. So, we asked Den to come on to be like, what is this thing? How do you use it and why would you want to use it and what does it look like? So then totally first is specd driven development.
(06:57) Did I actually nail anything about specific? You did you you actually did like it's it's people over complicated a little bit because they think it's like spec driven development is this like magical thing that has like a bunch of complexity involved in it's like and realistically all it is it's like prompt engineering on steroids. Is that is that a good way to put it? I think so.
(07:18) It's basically look I if you are working on a project with um NLM right if you're you're if you're building something that is using AI and you have to build it in the way that you the developer want it to be like what do you do right like you you have to give instructions to the you have to write out the instructions to basically provide this context to what you're actually building and how you want to build it and what tech stack and all these things right so spectriven development is basically you spending upfront some amount of time to go and define that and then have the LM build exactly
(07:48) what you wanted per specification. This is especially important if you're working on a team or a project where there are specific constraints like what if your team is using I don't know Nex.js JS or maybe you're using Vite or you're using some no framework at all and you have to kind of steer the LM like across your entire company of saying like hey whoever is vibing on any you know landing pages and anything like we always want to make sure that it uses Nex.js GS we always want to make sure that it uses Cosmos DB for data storage and all these things right so when you
(08:17) have specs that kind of guide a lot of this stuff you can create these constraints not only that but think of how the the inversion here works a little bit is that right now we treat code as this artifact that we like you check it in through a repo that's the source of truth right like code is everything but code also binds you to a very specific implementation right like if I am running um you If if I'm creating a website for like a podcast or a landing page, uh if I write the code, that's it. That that's that's the implementation,
(08:49) right? And if I want to create like a new variation of it, I like I wonder what this page would look like if it, you know, I rearrange the tiles differently or I had my login screen be different. You basically have to reimplement this thing from scratch. You have to go and rebuild it and figure out how to do this.
(09:07) The spec acts as kind of an inversion of this model where this the spec is agnostic of the implementation, right? Like once you have the spec, you can guide the LLM to 10 different implementations and say like, "Oh, create me like 10 variations of this login page because the the kind of the constraints are still the same, right? Like you're you're you're building the the the kind of the scaffolding for it and then you let the LLM cook.
(09:28) You let it let it do its thing and you I I had to sneak it in, but you got to let it cook. You got to let it cook. That's that's what SPEC driven at a high level is. So it's basically you're encoding context up front. So then you have the freedom to explore like various implementations, various, you know, variations of the project that you're building. It's kind of nice. I like it.
(09:46) And I think this is kind of important because I've gone into different uh enterprises and they call these um things app factories. And this is this is something app factory. The whole idea is hey, we're not building one app. We're building hundreds of apps, right? Over and over and again, all for different functions and purposes and functionality out there, right? So their whole goal in the beginning, so this is like a decade ago, five years ago, you know, two two years ago when I go talk to these big businesses, it would be like, hey, listen, I'm just trying to
(10:15) figure out like what stack, what's the stack that I can standardize on to actually be able to enable my engineers to not have to relearn brand new tech stacks or have different tech stacks. So we can interchange team members that could say, "Okay, we're spinning up this app. Go take this person from here while this person maintains it and they'll move it over.
(10:32) " So here what I'm thinking is like with the the spec the spec sort of driven development is if we do a bunch of work up front even if you're doing one app or you're doing hundreds of apps you were then able to kind of templatize. So like that business is all right hey we're using .
(10:50) NET on the back end we're using React on the front end here is our specs for how we build applications today and now we can actually start to implement sort of plan out apps on top of it precisely because you have the spec that encodes your why and the what and then the rest of the pieces and we'll we'll show that later in a little bit but like the rest of the pieces are very much flexible.
(11:09) So if you write an application uh or you write the specification for let's say like a marketing website that you're building and at some point your team decides to move to like oh we're going to use .NET Aspire to do all these deployments. We're going to use like ASP.NET Core instead of React. Well like guess what? You're not rewriting your spec. Your spec is the same like you defined your what and the why.
(11:28) What changes is the how. So now you just need to redo the how. and and also the specking codes very well a point in time snapshot of like why is this the way that it is? What are the functional requirements? What are the things that are static? And by the way, like when we talk about spec, when we talk about like vibing in comparison to each specs also evolve like people treat them as static things, but they're they're really not.
(11:53) Like it doesn't mean that like once you write the markdown file and you check it into a repo that's that's it forever. You can change it as things come in, as your requirements change, as your product changes. But yeah, it's kind of fun area. How does this, you know, we've we've talked a lot and you and I have demoed a lot and people have demo like PRDs, requirement documents, like how does PRDS like blend into specifications? Are they part of it? Is it different? Because that's been my vibe, which was like the easiest way to do it is kind of like lightweight spectriven development. I want to build this thing. Let's create a
(12:23) PRD based off of it. Do some market research. is like is that part of this process or is it different? It absolutely is. Um I do want to call out the fact that like you you say PRD and to me like there there's several kind of pieces. Sean says PRD because that's the first thing that's the first thing everyone says is PRD.
(12:41) I didn't know Amanda was talking about it. You were talking about it. I just asked Copa what the heck is a PRD? Product requirements document. That that's basically and PM PM speak for spec. That that's all it is. That that's uh it's a spec document.
(12:58) So, uh, when you write a PRD, that's kind of you you define the what and the why, like what are we building and why are we building this, right? Like you're not really focusing too much on like the how the technical implementations like which APIs do we use and where do we plug them in and how do we scale this? It's more about what is the solution and why what's the grounding data? We have customer insights.
(13:16) We have some rationale for it and that that's what the PRD is. But in our respective development process, we we essentially split up the PRD from the how and then a detailed breakdown of tasks that the LM needs to follow to execute on on the plan and the PRD that underpins it. So we'll we'll actually like maybe maybe we can show it. Yeah, let's look at it.
(13:39) Well, because this will be interesting because PRD means something totally different to who you ask. Like if you ask I have a template that I use for my PRDS. guarantee you it looks nothing like probably what you've got. So I'm curious to see like what this looks like here. Okay, so we have this project. It's called SpecKit. It's open source. It's on GitHub.
(13:58) And by the way, it's all it is. It's essentially a scaffolding set of templates. Like we've we've experimented with this with uh our good colleague John Lamb. Shout out John. He who did the initial like a lot of the work here. So um what I like to do Dan really quick when you you do go John Lamb. John Lamb. Oh, wait. Let me get the hand horn out.
(14:18) Oh, you guys came prepared. I I look at that. There you go. Oh, yes. Thank you. Shout out John Lamb. Um, but anyway, so, uh, we're going to look at the specit. So, specitate, like I said, it's a set of templates, essentially scaffolding for you. And because we want to make it easier for folks, we actually built a little CLI here that you can use.
(14:41) So, if you scroll to install specify, specify is what we call the CLI. You can use this. It's built with Python. Uh, and we're going to use UVX because uh, UV is freaking awesome. And what even is that? Is that like npx? Yeah, is basically is npx for Python. Okay. Oh, and there's like a DNx now, too, which is the net one as well. That's DMX. That's meet me outside. My rough riders.
(15:05) Yeah. What's his name? Um, DMX. Uh, so so let's say you didn't have this. Could you just clone this template and start or is it Oh, yeah. If you if you if you do not want to use a CLI, if you're not installing Python for whatever reason, totally fine. Uh we have releases.
(15:23) So, if you go to Spectit templates, uh and by the way, we support Copilot, Cloud Code, and Gemini CLI. So, we are, you know, spanning the platforms here. Uh but you can also download these templates. They're they're zip files and just use them directly with your project. So, you don't actually need to jump through the hoops of the CLI. Well, time to uninstall Python and UVX.
(15:40) Get out of It took me eight days to figure out how to get my Mac terminal to work. Now, now I have to use it. So, yeah, now now you have to use it. But, uh, the easiest way to do this is to essentially use specify through UVX. Uh, and now D. Yeah, sure. Specify because it's a spec kit. Specify. I This is up for debate.
(16:05) This is up for debate. I'd say like we we had that conversation. It's I call it specify. Some people call it specify. You can call it whatever you want. It's like specify means something very different than No, it doesn't. Same word. All right. Well, right. Word for us all to miss. This is the show where we get nothing done.
(16:27) Yeah. The GIF and GIF the debate all over again. Um, so we use specify init. Uh, and then we're going to give a project name. I'm going to let it cook. uh test. All right. And when we do this, we're going to get the nice little installation prompt to get the the cool ASKY art. Oo. Did you spend a lot of time on that, Dan? Uh just just a little bit more than the rest of the CLI.
(16:57) Uh but um you could just like you would in, you know, if you use any of the existing AI LLM CLIs, you can use your keyboard to navigate through the agents that you want to use. Uh, and in our case, we're going to use C-Pilot because of course we love Copilot. And we're going to say yes. And then it's going to initialize our project.
(17:14) What this does, all it does is just pulls a template. It pulls the latest release, unzips it locally, puts it in a folder, bootstraps a Git repository if you do not have a Git repository. And by the way, you can do this in an existing project. You don't actually need to start this off in a whole new folder. But what do you have stuff to the existing project? Totally. Yeah.
(17:32) If you have an existing repo, just add like what I just did in the I use let it cook test as a name. You can just add the name of the folder of the git repo that you're using and it was just going to bootstrap all that in that repo. Or if you're like me, just put it in the wrong place and then copy and paste or put in the wrong place and copy. Yeah, it's fine.
(17:50) Again, these are all this is scaffolding. Like none of the stuff is immutable where you're like, ah, now I put stuff in a registry. Like it didn't do any of that. So, uh, we're going to go to our folder here. This is C and test. Okay. And in this folder, if I do tree, you'll notice that actually bootstrap a bunch of stuff.
(18:10) So there is like some memory and we'll we'll look at this in a second. Some helper scripts which also they're they're shell scripts by the way. They you would need WSL or Linux or Mac OS, but um you're in WSL currently. I'm in WSL right now. I'm using auntu. That is the Windows subsystem for Linux. I am working on PowerShell scripts. So, it's coming. Yeah. But for for a test is just shell for Sean's about to get real bent out of shape.
(18:33) I'm I'm already bent out of shape. If it's not a PS1 file, get out of here. Yeah. Um and there's a bunch of templates for what we're actually going to do. And I'll I'll show this in in VS Code. But, uh I'm actually going to do tree and a to see that there's actually missing pieces here that I'm going to scroll up to the very top past all the git stuff. And then we have the GitHub folder here that has three prompts.
(19:00) Specify plan and tasks. And we'll use them in action. And this is the stuff that you saw here when specify bootstrapped the project. It actually hinted it's like and open Visual Studio Code and use specify plan and task commands.
(19:19) That's you know we use the existing built-in capabilities of VS Code to pick up prompts as slash commands which is kind of neat. I I really like that that that once I talked to Pierce about this is a made it a no-brainer. Just plug it in. So, we're gonna WSL is called Weasel. No, it's not. No, it's not. No, no, no, no, no. Absolutely not. Now, it will be forever, I guess. I guess I'm going to call it that from now on. Like, I'm going to be getting a call from the Windows marketing team if I use that.
(19:41) Like, yeah, this show's going to Thanks. Thanks. Now we're cancelled. So, we did get a question earlier that says, you know, you know, we're on VS Code, but can you use with Visual Studio? And the answer is like, yeah, you can just if it's prompt files like you showed, you can run prompt files inside of Visual Studio as well. They're prompt files.
(19:59) I mean, you could take what's in the prompt and I guess run it anywhere technically. So, yeah, I mean I mean none of the stuff here is actually designed around VS Code as experience. Like you you can use, you know, Sublime Text if you so desire. It's just the experience. I only use Notepad. So just copilot in notepad so it'll run it.
(20:16) You know it's like I I saw people write like Linux kernel contributions in like literally just a plain text editor. I was like what what happened in your life that led you there? Joy. Why? Why joy? Why do you hate happiness? Um so um as I mentioned so we have the prompt files we have the specify uh which again just defines like what needs to do what the what the agent needs to do and this is essentially for defining that PRD James that you were alluding to this this the specify command is for that feature specification that outlines the what and the why. We're not focusing
(20:51) on a technology and of course we are using our helper shell scripts here. So you you can you can tell that because when we create a new feature, we want to spin up a new branch for it. We want to make sure that it's actually in a new folder that the spec is actually written. So it's not polluting the rest of your codebase.
(21:11) So all all it does is just kind of defines the logistics of the the feature spec. Then there's the plan. The plan is our how piece and this is building on the feature spec is how do we actually build this? What tech stack do we use? What databases? What you know performance things we need to consider? And it's also grounded in this thing that we call the constitution.
(21:29) And constitution is kind of a can sound like a scary thing, but the constitution essentially is a set of non-negotiable principles for your project. So if I'm building a web application and I want to make sure that my organization is always using tests, I I am always shipping code that is grounded in read red green refactor cycle. Like I I can enforce this with a constitution.
(21:53) Like the constitution is essentially non-negotiable. Whatever you build, whatever plan you establish, whatever task you break down, this document always has to be followed. This is there's nothing in it, right? There's nothing in it because we not yet, we haven't started anything. Okay. Okay. Um but this is distinct from things like we've seen before with cloud MD like agents.
(22:16) mmd because those are kind of like giving you the context of the project, right? Oh, this is a web application and you can open these files and you can use a CLI tool. This is specifically around the fact that these things should always be followed. Um and then the last one is the tasks prompt file. So this is where we just break it down all all the plan that we have into task and it gives you the logic for how to actually do that.
(22:36) Right? So um it references a bunch of documents that are going to be created post factor that we're going to see in a second. And as I mentioned like it pulls in helper scripts and it pulls in some of the templates that we're going to use for the plan for the spec and for the tasks. So again all this is scaffolding. It's markdown files and shell files. That's all.
(22:56) Yeah, like it's it it's really like the CLI doesn't do any magic other than like putting this stuff in your folder. But um anyway, let's let's see this in action a little bit. So, I'm going to open our favorite agent mode here. I'm going to be using GPT5. And by the way, depending on which model you're using here, I don't know like you guys, what's what's your model? What do you prefer for coding? Well, I was about to ask, Dan, because you're going to get quite different results depending on what model you use here. I would I would expect that that Claude probably works the best here because there's so many different
(23:25) instructions and it's really really directable. Um 4.1 is my model of choice, but I don't know that 4.1 is going to be able to to do what what needs to be done. I'm curious. I'm a five five mini is my jam. So five is really good. Five is underrated. Like John and I John Lamb and I talked about this and like GBT5 is really really good at coding lately. I actually haven't touched on it in a long time.
(23:51) After all, I I default I default to five and then if I really need some vast exploration, if I want someone to hitchhike through my code, then I I pull up Claude and I say, "Let's yeah, let's go on a backpacking trip through my my code base." Yeah, you you could absolutely do that.
(24:08) Uh, and by the way, this is this is also the beauty of the spec driven development is that you can apply this process to an existing codebase and then basically pull in the context from your code and have the spec be on top of the existing codebase and conventions and everything that you've created. But anyway, uh let's let's get the constitution rolling here. So, um because I'm we have limited time, I'm not going to write the constitution from from scratch.
(24:31) And let's just ask GPD5 to help us. And we're going to say let's update this constitution for a web application set of constraints and let's see what it comes up with. I I'm genuinely curious. I have not done this before. Like all the constitution documents that I put together were basically just me putting constraints.
(24:53) So we'll see if agent mode can come up with some, you know, decent set of requirements here. So is this the first thing that you would actually do is like update the concept? Oh, okay. Okay. So you so you're not even running the scripts yet. You're just like no not yet because I just want to make sure that like I'm grounding my project in some set of kind of non-negotiable principles and you know typically again for this is helpful when we talk to enterprises what things that they do is like oh I only want to use the Azure CLI for deployments like this. This would go here. I only want to use Azure services
(25:23) like functions and app service and whatever else like this stuff goes here. You're essentially defining the hard constraints that you cannot get out of whatever you're building and it's sharable. So you can use this across your org. You can share with other teams and they can reuse it.
(25:40) So it's not something that you necessarily need to put together every single time. It just happens that in our sample we don't have anything because we don't know where you're going to be building. Yeah. Where is it pulling these constraints from? So these constraints right right now it's going to just pull it from its training data. Okay. Right.
(26:04) Like but you would imagine that in your organization you might say like your your CTO says like you always have to use Nex.js for every web app. Right? You just write this manually. This is like when I was talking about the app factor. It's like we are doing this we use this you know we use this deployment method. We use you know uh GitHub actions. We use blah blah blah. We this is like this is like our color you know this is our branding. This is our color. This is blah blah blah. Right. Yeah.
(26:26) And look, it actually did come up with like a decent set of requirements. If we look at the like it userentric accessibility first, like that's important. That's nice. Secure by design, lease privilege always like all right. Yep. Maybe for our like our our podcast landing page is not that important, but like you would imagine that for an or like sure.
(26:44) Um and because in the constitution template we had examples, it actually fills it out like based on those examples, which is kind of neat. So we have the constitution. Let's actually get it to write us the spec. So we're going to use the slash command. I'm going to use specify. Going to just call it specify from now on. Like this is just You're welcome. Like Yeah. Thank you.
(27:02) I'm really good at naming as I'm going to say specify whenever I use the word specify in any context. Just let people correct me. Can you specify what you mean exactly? Uh what I'm talking about here. So So when we define a spec, we use the the slsp specify command. We essentially define as I mentioned several times, it's the what and the why.
(27:22) So you're not focusing yet like oh I want to use net or nextjs you're saying I am building a podcast landing page make it modern dark theme is it going to be a podcast landing app so for for the what is it for is it like a podcast app like where people can like download stuff or is it like I am a I am a podcast like for the podcast yeah I'm building a podcast landing page for my podcast the vs code insider podcast. All right.
(27:55) I mean, you you told me to specify. Yeah. Yeah. And by the way, that's actually a very good point. The more concrete you get here, the better. Like the the results, right? Like if you if you have like a vague like, oh, I'm just building a landing page. Like it's going to produce like garbage results because like it's going to just fill in a bunch of assumptions for you. But the more specific you get here, the better.
(28:14) So podcast landing page for VS Code insiders. Make it modern. dark theme speakers on the main page for featured conversations and you got the specify commands because and was asking in the chat how' that happen in case you're joining late when Dan ran the command he asked did he want copilot gemini or claude CLIs and what it that did is it scaffolded out in this case for copilot thegitub/prompts and it put those prompts inside of in this case VS code picks them up automatic in that folder or Visual Studio would as well. Yeah.
(28:50) Yeah. At least 20 mock episodes. All right. So, uh I'll do this. It's good enough. So, you'll notice that that the follow instructions when I when I type this into chat, it says follow instructions specify.prompt. So, I use a slash command, but it knows because I have the GitHub folder here that it's just going to, you know, follow the instructions from the the the actual prompt file.
(29:14) It's the slash command is a prompt file. That's all it Well, would you would you so here you're scabbling on something new, but if this was in an existing application, would you do this like I I'm adding a new feature to this applica. If I'm just adding a new fe Okay, so if I'm adding a new feature, I would I would spec specify the feature. Exactly. It's Yep.
(29:32) It's it's very much universal. And notice that actually ran the bash script, the helper bash script for actually bootstrapping things properly here. So now I have a specs folder with a 001 feature name because it did not properly identify the feature, but that's okay. Um, there's my terminal where it actually ran and now it's just working on the actual spec file.
(29:49) It pulled in the template and the template is just blank because it doesn't have any requirements just yet. Uh, but it's going to fill it out and GD5 I recognize the functional requirements. That's that's how I do my PRDS. Yeah. Yeah. Yeah. So, this does it for you automatically because we have the template.
(30:06) Um, and GBD5 can be a little slow in this regard because it just has to fill out everything from like in one go, which can be, you know, depending what you like, what you don't like. Um, but it it I I use GPT5 and it work just just fine in terms of producing the code and the output. So, um, let's see. Report. I actually like this little task box. Yeah, that's the jam. All right. So, we're working on improving those too right now. Yeah, it's it's it's really neat.
(30:32) Like I tracking the status of that is Yeah. So, uh it actually noticed that it actually focused on things like acceptance scenario, user story. So, stuff that typically PMS would write that it just did it by itself. And this is not immutable. You can go in and change things here.
(30:50) Um but it did come up with functional requirements like filtering or discovery of episodes by tag or thematic grouping. Like I didn't type any of the stuff, right? Like um but it's kind of nice. So I see that there are some things that need clarification and specifically one of the things that is very important about spectrum of development is that this is not just vibe coding in terms of like oh I'm just going to vibe the spec and I'm just going to vibe the plan. You still have to review it. You still have to look and make sure that it it produces the right
(31:15) things to help with this. We also added this thing called the acceptance checklist that you kind of have to go through and make sure that it actually fits the requirements that you've established. So um in in our case we have requirements around things like content quality and requirement completeness and for example you cannot move forward until no need clarification markers remain. And we we saw a couple of them.
(31:42) So because I'm lazy I'm just going to say fill in uh the clarification hallucinate answers as best as you think. Uh so let's let's just have it do it like because this is a non-production application. we're not worried. But you would imagine that me coming in here as an enterprise saying like, "Oh, yeah, I do need to specify the the latency requirements for my project.
(32:06) Like I can't really let the LLM guess that for me, but you know, for a landing podcast page, that's fine." This is cool because like um you know, Lee was asking here like about the green field projects. I have feedback flow which I 100% vibe coded and what I ended up doing was doing a lot of the documentation after like, oh, you just implemented this feature.
(32:22) do, you know, after I've worked for hours to get it right based on what I had in my mind and we worked together, me and in the the GPT. Um, in this case, I could actually just do this on a new feature that I'm adding. I think that's what that's what I'm going to try now is like, you know, I do a lot of new apps, but then I could see myself exactly what I've done here because I've done this sort of process, but not Yeah. in as much detail. Uh, for sure.
(32:45) I like I like your frame like we were working me and the GPT our best friends me me and co-pilot and GPT and Claude and all they're all in my and this is where I get I start to get skeptical spectacle spectacle and I would like to tell you here's why yes because when you are specking out a green field app especially right which is less common you don't know what you don't know correct this is this is how programming works you think that you're going to do something one way you try to do it that way. You realize, oh, that's not actually going to work, but it's kind of
(33:16) going to work. So, I'm going to need to to shift slightly, right? And so, you can't. In theory, if you could tell the model upfront everything that it needed to know, it would give you the right answer. Prompt engineering is just giving the model the answer that you want. But we can't.
(33:33) That's really, really hard to do. Yes. Like, you would have to spend hours thinking about the feature, examining every edge case. Yeah. And I just don't I just not sure who out there number one can do that me. But number two, more importantly, like who wants to do that? I think I think a lot of businesses do. I think a lot of like PMs, a lot of a lot of I mean a lot of like I think a lot of folks today like work off of a ticket system and they they refine and they put in specifications into tickets before handing it off to the engineers. Now, I mean, I think this is really big because this is like a huge thing, but
(34:11) my assumption if I had a small feature, it'd be a small specification hopefully. I I will also add to this that you're absolutely right, Burke, that this this is the kind of stuff where it's like you you you don't know what you don't know, and if you go down this path, the kind of the wrong assumption here is that you need to have everything from the get-go and then once you start, you cannot go back. But you can. So once you actually go to the product and it builds the thing and you realize like ah crap I did not
(34:37) implement the the login flow the way I wanted you can just ask it to reimplement it and encode that in the spec right so like you can you can go essentially go back and say oh right the login flow doesn't work the way I expected it to go and go and redo this and make sure that this is properly reflected like it's not a oneshot thing yeah and that makes sense I guess I just in my own experience here Den what find happens is that I create these plans and specs and then somewhere in the process I'm just like, "Yeah, it looks good
(35:07) enough, right?" And then I just send it and then it just cooks up a bunch of code that I don't understand and then like four iterations later I have no idea what's happening in the code of the project. I'm just clueless, right? I'm just like plan spec. Yeah. Right answer. Realistically, this is the kind of stuff that like you you you would end up in a state of I need to be able to break this down for the model in and that's what we're trying to do in these like composable chunks. It's like you're not just writing one document and let it do it. Just like, oh, I need this
(35:39) other feature. Let me just add this other specific feature requirement. That that's that's kind of what it is. I wonder if maybe the answer here is like breaking your tasks down into very like the smallest possible bingo. That that's exactly what specify does. Yeah. Um so the second command is where I can do plan and essentially this is where I can say like plan and uh for plan use next JS old data is mocked because we're not using a database.
(36:11) No databases or six minutes then to I know I know we we'll get we'll get to this we'll get to this. Uh so um all all of this stuff like it it's essentially it's a it's a process and by the way like when we talk about the process here the stuff that you see the scripts the templates all of this is very much experimental like if if Burke James like you guys go in and try this be like Dan this is a pile of garbage like this does not work for what I'm trying to do and it just does not produce right let us
(36:41) know like this is the kind of stuff that we we actually this is why we we released it to begin with is we want to get feedback we want to get input from folks and see like where it works and where it doesn't. And if you're trying to build a web app, you're trying to build an iOS app and this is not working. It's producing incorrect output.
(36:59) Like we we'd want to know that because we've experimented extensively internally on like prototypes and projects. I actually like built a prototype for one of the exact demos with this just the other week and it worked like really well. Wow. But I'm just one person, right? Like I'm I'm not I'm not either of you. I'm not the community watching this.
(37:18) So very much like this is not like a final state like what you see here is going to be forever this way just to caveat this that makes sense. Now all this stuff that is generating this spec and research stuff fuel was asking like does that gets checked in as part of your codebase basically? Yeah absolutely because the spec becomes yeah the living breathing document that you can use and your team can then refer to and look and say oh I get how they landed on this feature.
(37:48) I understand why uh that that's and again because once you have the spec you can easily go and reimplement it. You can just rebuild it from scratch because you have the spec. That makes sense. And then yes are saying like when you add a new feature to the spec ideally you have the specs for the other things. So it should reliably kind of know how to update and what it needs to update and search through specification documentation.
(38:06) Yeah. Yeah. Exactly. And and this is the kind of stuff where you you you end up with a a set of kind of artifacts that are very much reusable by the team. And in our case, like the research here, it's pulling this from the training data. Uh and I actually need to use Burk's like beast mode probably here to do some like force it to go and do some Google searches for um what the right framework should be like for Nex.js, right? Oh, Burke, you're muted.
(38:32) I am I am muted. Whoops. Uh, beast mode doesn't work great with GPD5 because GPD5 doesn't really do well with like longer prompts, right? So, because it gets appended to the end of the system prompt, it tends to just ignore all of it. Yeah, because the beast mode prompt is pretty pretty big, right? Like it's pretty it's size and it's meant for 41.
(38:55) It's specifically formatted for that model. Although Claude is so directable that it will also pay very close attention. But yeah, y'all chat have not had great luck with uh with GT5 and beast mode, but but I love beast mode because I've actually experimented with it like the other day and it was totally fine.
(39:12) Um and it the fact that it forces to go and search is great. And this is something that I love about like claude code like if you folks have used it like you know like oh let me go and search this but like it does the research for the phases. It does the breakdown and notice that in my plan I'm I'm going to keep all this.
(39:29) And really quick too, someone was asking in the chat like you ran the plan. Did it how does it know to grab that information from the specify specify step. Oh, because all this is encoded in the the So if you look at the plan, right, it it actually encodes a lot of this information, right? So it says run the script, read analyze the feature spec, and it knows where the feature spec is because we just created it. Like it's it's in the conversation history.
(39:53) And then it also grounds it in the constitution as we mentioned like you know read the constitution to understand the requirements. So this is the stuff that we know are non-negotiable and then apply the template right so it's all like it's basically chaining prompts it's it's chaining prompts together and chaining a lot of the script activity together as well.
(40:07) Um, and then lastly, once you have the plan, we just say tasks and then uh break down the plan into tasks. And this is going to create the the task that Burke was talking about, like the the smallest chunks possible for every single section of the plan.
(40:25) So, what was created in the plan really quick cuz I see on the spec feature while that's cooking. Yeah. So, the the planet has again technical details, technical design. Uh so if we look at the kind of the layout here, it outlines the project structure. It proposes the the source code structure as well, which is kind of again neat for for me to see. And if I like, oh actually my teammate does not maintains SRC or SLS SRC, you you can update this very very easily.
(40:50) Um and then uh yeah, so like testing non-negotiable because we encoded that in a constitution. It it is required. So it puts this observability versioning. Delete that. Just delete that. Yeah, of course. No, we don't need that. Um it has the reference to again the kind of the research document but outlines like what is the oh using Nex.js like let me talk about Nex.
(41:07) js and if we go to the research document that it produced you'll notice that it it talks about use next.js app static generation for landing blah blah blah and all this stuff. So it it it cross references a bunch of these things in the plan to essentially say like this this is this is how I'm going to approach building it.
(41:25) So remember the spec is the what and the why. This is the how. And it has all these kind of requirements constraints like mark independent UI components and you know setup and tooling which is required for this because we're using TypeScript and X.
(41:42) js but yeah it's it's technical requirements basically and you can adjust these as well because all the stuff gets checked into the repository all of it. It seems like some of this stuff Dan you would want across multiple projects right like Oh absolutely yeah you would some sort of a where you could just pull it in to new projects automatically. Right.
(42:00) Right. Right. So like I mentioned the constitution is a good example which is like my team is always building web apps that follow these constraints. Just reuse this like I don't need I don't need everybody to write their own constitution document. They can just reuse this. So but to the point of task so it seems like it finished.
(42:18) So we can go and look into tasks and you'll see here that let me just close this. There's create front end add typescript like it it basically broke it down into different chunks. write schema validation test for episodes like these are workable chunks that it can now tackle. So I don't need to wait for it to go in and say, "Oh, it's it's it I mean it's still going to be non-deterministic, but the tasks help it steer it in the right direction and say like, oh, you need to implement the audio player wrapper component and now you do this and now you do this." And it's like it has very concrete instructions instead of guessing.
(42:49) And I I tried to do some uh yolo spec driven development by myself, you know, because I couldn't get stuff running on my on my Mac in time in the morning. And what ended up happening is I was going back and forth with like my PRD and this and that.
(43:06) And because I'm having it generate all the code, I didn't have time to like review what is in like and this was like my my pet tracking application for my dog. Um was like okay like what actually isn't a pet? Like what information they need? Like how is the user configured? What is this? So like it went off and then I spent a bunch of time like actually fixing it and trying to go back and forth that now I think I'm just going to throw it all away and start over with this because at least for me I can understand and say okay like here is what's in this part and here's what's in this thing. Yep. Exactly.
(43:32) Now now Dan Dan I would like to ask a question here. Um yes. So one of the things that you're actually fighting now is the fact that um GBD5 and Claude are both crazy slow and you've got a long conversation. So you're hitting summarizing conversation history which is also slow. Something we know about. We're working on it. Now here's my question.
(43:56) GBD5 Mini and 41 are really really really good at following very specific instructions. If you tell them exactly what to do, yeah, they can do it. What they are not good at is when you give them a broad set of constraints and they have to try to fill in the blanks. My question is could you switch to GPT5 mini here and have it implement the tasks? Yeah. The the model here of result. Yeah.
(44:20) Yeah. The model here is your choice like I'm not bound with a GP. I'm just using GP5. I'm just in your in your experience in my experience like I like I I have noticed that GBD5 and the mini variants can be very good. Exactly as you mentioned like they're precisely following your instructions and not going off the rails.
(44:38) The one thing that actually is helpful to have the constitution and a lot of these documents for is for like sonnet models because they go off the rails super quick. They're they're overeager. They're very eager to go and do a bunch of stuff because I mean they they were like rled in a bunch of code. So they like coding.
(44:55) They're going to just just let me code a bunch of stuff you did not ask for. Um I see you don't have a podcast. Let me create that podcast. Yeah, exactly. Like you're absolutely right. I did not think about the podcast. Uh, and you know what's interesting is I I've generated MP3s with you. I I tell Claude, "Do not ever say you're absolutely right." And it will say it no matter what you do.
(45:14) There's nothing you can do to get it to not You're absolutely right. I should not be saying you're absolutely right. You're absolutely right. You are absolutely right. But uh so yeah the the model and also I'll say like experiment with the models like try out different like switch them and see how the implementation looks like because what I also noticed if you use GPT5 sometimes what what sonnet is really good it also can be creative.
(45:38) So if I like in my initial prompt when we use specify actually asked to like make it modern if you look at the sonnet output it's going to produce like a site that can be very like dark theme some like maybe like overlay some really cool stuff. GBD5 will produce potentially like a a white page that is just like bootstrap style UI. It's like, oh yeah, it's modern. I follow your instructions.
(46:01) But like it's it doesn't have that same creativity in it. So those kind of things matter. And again, you you have to test it. You have to try it and see like what what it produces, what it works, what doesn't. For the spec pieces and the task pieces using precision models like GPT5 are like perfectly fine.
(46:19) But then once you have this, once you have the spec, the tasks, the plan, you can experiment with different models and see what outputs you like best. I'm really excited to see what this actually turns out here. Yeah, it's going to like I don't know how long it's going to take, but um it is cooking. It is it is cooking on something. See five minutes late to your meeting with Satcha or whoever it is. That's that's fine. Satcha can wait.
(46:38) Yeah, that's not at all a career limit. Sorry, Sati. I do not agree with that if you're watching this podcast. If anything, yeah, it's just like we were sort of B James and I were just building a podcast website. We just really need We're just cooking. It's created 25 files.
(46:55) So, I mean, and the other stuff too. Oh, now it's creating your your contracts. So, it took like put like some playright and some just configs in there as well. Oh, it did create it created a Yeah, play playright test config. It has all the stuff. Icons. What icon pack is this? Uh, this is the cat puin. The what? I think it's called the cat pooin. Like the cappuccino, but there's cat puccino.
(47:18) So it's like interesting. It I've never heard of that one. Yeah, it is. Let's see. Install. Yeah, cat poo for VS Code. I got to get that material is like the goto. So yeah, you're the trend. Yeah. Yeah. I I I'm I'm not really a trend follower here. Um, you're the trends setter, Den. Obvious. I love this, man. I want to try this. Like, I'm going to do this as soon as this is over. Seriously, I've got stuff I'm working on today.
(47:45) I'm absolutely doing this. And like I said, it's not perfect. I'm sure there's things that are going to be broken. I'm sure there's things that are going to be not working as you expect. I want to know that. Open an issue in GitHub. Ping me directly on Blue Sky or Mastadon or LinkedIn or wherever you find me, wherever you find this podcast. Uh, we're again, it's it's an experiment. We're here to learn.
(48:03) Yeah. Harassed in online. harass. Yeah. Well, that's I should not be saying that. Like, subscribe. Quity, positively. If you want quality, if you want quality content, which this uh live stream is not, follow Den because Den's busting quality. I'm just Why? Let's just be honest with ourselves.
(48:24) Burke, I'm not like like Claude over here with self-gratification. Oh, you're totally right. This this YouTube stream is awesome. It is. For once, I'm not talking about MCP, right? Like I I can talk about things other than MCP. You've moved on so quickly. No, I'm still an MC. What do you I'm still an MCP. Is just this. I'm doing both. I'm doing both. Wow. Man of multiple talents.
(48:48) Someone's using this live. It's happening. Feels good. Oh, wow. Using it right now. Let's go. Let's go. Feels good. Feels good. That That's good. It's like, you know, it's got good It's got good kill better than feels bad.
(49:04) I see Hashim was also mentioned like it would be interesting to use claude for the design task and GPT5 mini for or GPT5 mini for precise stuff like writing test and yeah absolutely I mean again try it out like the the easiest way to see what works is to swap models and just see see what works for your scenario cuz like I've for web apps by the way also depending on what you're building I've seen if I'm building a desktop application for Windows like I'm building a console app like GBD5 is excellent if I build a web app I generally get better results with sonnet but not as much if I build like Windows apps. So, your mileage may vary
(49:35) here. How many packages are you installing? There's a there's a bunch. And also, really cooking on those. It is really Yeah. Like I'm I'm sure this is totally not going to bring some like super vulnerable like hallucinated packages. No audit. It's like no audit. No, no.
(49:53) I I like the no audit that basically like I don't care about vulnerability. Just pull whatever. Uh yeah, we did not encode that in the constitution that it should audit things or we can look at the source pricing of the top models. Well, we could talk about that while this cooks a little bit. So you have your premium requests which are So let's talk about included models which is GBT5 mini 41. Is 40
(50:21) still in the picker? It's still in the box. Yeah, still in the picker. 40. like we have and for a limited time Grock fast one is there but that I believe will be moving to a 0.25 multiplier. So those are your included models which means that they're they're unlimited although if you hit these enough you will get rate limited right like you can't burn $5,000 of GPU on 41. Sorry. Mhm.
(50:48) And then you have your premium models which are each uh these are called um each like um turn session with the agent is one is it turn no the a the turn is what the agent does. So so so uh like when when when Den did a plan that was the start and then when it stopped and it was like I'm done. That's one premium request. Correct.
(51:12) one premium request and I think if you're on the pro plan you get 300 of those pro plus 1500. So what you want to do and that's why I was asking Dan like if ideally what you do is you for people that are trying to ideally you would have this whole process automated and you wouldn't review any of it. Yeah, you could. Or you would just like tell the chat to like after you get to this step, just wait for my wait for, you know, five minutes, but don't stop. Just keep going. Yeah. I'm just trying to show people how to game the system.
(51:39) Yeah. It's a good experiment to try this. Yeah. So, anyway, that's that's the pricing. It's pretty simple, y'all. It's just priced on on agent sessions. You don't have to worry about tokens and all that stuff. Very cool. Well, this is spec kit. Like, you know, it's still here because the spec the spec kit part of it's done. Now, you just told it to implement. Now, this is just now I'm just waiting.
(52:04) I'm hand completely hands off. I'm just waiting for it to go and like build the stuff for me. So, and I know you got to move on, Dan. You want us to wrap it up here? I feel like the folks who joined today, y'all are the lucky ones because this is awesome. You just maybe turned Burke on to this, which is good. I'm going to go give this a try as well.
(52:23) What we'll do practical is Den will commit that code. So later today I'll go back to the YouTube page youtube.com/code and then look at this episode so we get our view count up. Like and subscribe and then in the show notes below we'll put a link on there and we'll make sure we we tweet it out. So follow Den Burke me VS Code on the socials.
(52:46) Maybe we'll have Olivia post it out as well on on as a followup of this post as well. Den go you're running out. Yeah. And I'll I'll commit the repo. I want to share what the outcome of this will be. I'm excited because we have a podcast website that we we pay for. So for you also there is a VS Code Insiders podcast. That is a real podcast that you can subscribe to on your favorite podcast application behind the scenes there.
(53:09) Um Dan, thank you so much for coming and talking through everything and showing stuff off and I can't wait to see when this cook finishes. Thank you for having me here. Awesome. Well, Burke, as always, an honor. Happy coding everybody. out. Bye. Bye. Bye. [Music] [Applause]